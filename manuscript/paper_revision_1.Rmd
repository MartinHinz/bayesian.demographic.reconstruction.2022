---
title: "Bayesian inference of prehistoric population dynamics from multiple proxies: a case study from the North of the Swiss Alps"
author:
  - Martin Hinz:
      email: martin.hinz@iaw.unibe.ch
      institute: [IAW, OCCR]
      correspondence: true
  - Joe Roe:
      email: joe@joeroe.io
      institute: [IAW]
      correspondence: false
  - Julian Laabs:
      email: julian.laabs@ufg.uni-kiel.de
      institute: [SFB1266]
      correspondence: false
  - Caroline Heitz:
      email: caroline.heitz@arch.ox.ac.uk
      institute: [SFB1266]
      correspondence: false
  - Jan Kolář:
      email: jan.kolar@ibot.cas.cz
      institute: [IBOT, IAMFAMU]
      correspondence: false
institute:
  - IAW: Institute of Archaeological Sciences, University of Bern
  - OCCR: Oeschger Centre for Climate Change Research, University of Bern
  - SFB1266: CRC 1266 - Scales of Transformation, University of Kiel
  - IBOT: Department of Vegetation Ecology, Institute of Botany of the Czech Academy of Sciences
  - IAMFAMU: Institute of Archaeology and Museology, Faculty of Arts, Masaryk University
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::pdf_document2:
    includes:
        in_header: preamble.tex
    toc: no
    pandoc_args:
    - --lua-filter=../templates/scholarly-metadata.lua
    - --lua-filter=../templates/author-info-blocks.lua
    - --lua-filter=../templates/pagebreak.lua
  bookdown::word_document2:
    fig_caption: yes
    reference_docx: "../templates/template.docx" # Insert path for the DOCX file
    pandoc_args:
    - --lua-filter=../templates/scholarly-metadata.lua
    - --lua-filter=../templates/author-info-blocks.lua
    - --lua-filter=../templates/pagebreak.lua
bibliography: references.bib
csl: "../templates/journal-of-archaeological-science.csl" # Insert path for the bib-style
abstract: |
  Robust estimates of population are essential to the study of human–environment relations and socio-ecological dynamics in the past. Population size and density can directly inform reconstructions of prehistoric group size, social organisation, economic constraints, exchange, and political and social institutions. In this pilot study, we present an approach that we believe can be usefully transferred to other regions, as well as refined and extended to greatly advance our understanding of prehistoric demography.
  Here, we present a Bayesian hierarchical model that uses Poisson regression and state-space representation to produce absolute estimates of past population size and density. At its core, the statistical model is as follows: if the proxies as a whole have a positive delta, a Poisson draw for the new number of settlements is biased by a positive amount (and similarly for negative deltas). Using the  area North of the main ridge of the Swiss Alps in prehistoric times (6000–1000 BCE) as a case study, we show that combining multiple proxies (site counts, radiocarbon dates, dendrochronological dates, and landscape openness) produces a more robust reconstruction of population dynamics than any single proxy alone. The model's estimates of the credibility of its prediction, and the relative weight it affords to individual proxies through time, give further insights into the relative reliability of the evidence currently available for paleodemographic research. Our prediction of population development of the case study area accords well with the current understanding in the wider literature, but provides a more precise and higher-resolution estimate that is less sensitive to spurious fluctuations in the proxy data than existing approaches, especially the popular summed probability distribution of radiocarbon dates.
  The archaeological record provides several potential proxies of human population dynamics, but individually they are inaccurate, biased, and sparse in their spatial and temporal coverage. Similarly, current methods for estimating past population dynamics are often simplistic: they work on limited spatial scales, tend to rely on a single proxy, and are rarely able to infer population size or density in absolute terms. In contemporary demography, it is becoming increasingly common to use Bayesian statistics to estimate population trends and project them into the future. The Bayesian approach is popular because it offers the possibility of combining heterogenous data, and at the same time qualifying the uncertainty and credibility attached to forecasts. These same characteristics make it well-suited to applications to archaeological data in paleodemographic studies.
keywords: |
  Prehistoric demography; Bayesian modelling; Multi-proxy; Settlement dynamics
highlights: |
  - Bayesian modelling can integrate multiple, heterogeneous population proxies from the archaeological record
  - Our initial model produces more robust, high-resolution estimates of past population dynamics than previous, single-proxy approaches
  - We provide absolute estimates of population size and density on the area north of the Swiss Alpes in prehistoric times (6000–1000 BCE)
---

Keywords: `r rmarkdown::metadata$keywords`

Highlights: `r rmarkdown::metadata$highlights`

```{r setup, echo = FALSE, message = FALSE, warning=FALSE, results='hide'}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  comment = "#>",
  fig.path = "../figures/",
  dpi = 300
)

library(here)
library(ggplot2)
library(ggmap)
library(cowplot)
library(sp)
library(sf)
library(ggsn)
library(rnaturalearth)
library(ggrepel)

switzerland <- ne_countries(country = "Switzerland")
bbox_ch <- bbox(switzerland) %>% as.vector()

switzerland_bb <- st_as_sfc(st_bbox(switzerland))

swiss_background <- get_stamenmap( bbox = bbox_ch, maptype = "terrain-background", color="bw", zoom = 8)

rivers10 <- ne_download(scale = "large", type = 'rivers_lake_centerlines', category = 'physical') %>% st_as_sf()

rivers10eu <- ne_download(scale = "large", type = 'rivers_europe', category = 'physical') %>% st_as_sf()

lakes10 <- ne_download(scale = "large", type = 'lakes', category = 'physical') %>% st_as_sf()

lakes10eu <- ne_download(scale = "large", type = 'lakes_europe', category = 'physical') %>% st_as_sf()

my_basemap <- ggmap(swiss_background, darken = c(0.6, "white")) + coord_sf(default_crs = st_crs(4326)) + geom_sf(data = rivers10, color="lightblue4", inherit.aes = F)  + geom_sf(data = rivers10eu, color="lightblue4", inherit.aes = F)  + geom_sf(data = lakes10, fill="lightblue4", color=NA, inherit.aes = F)  + geom_sf(data = lakes10eu, fill="lightblue4", inherit.aes = F, color=NA)

my_scalebar <- scalebar(transform = T, dist_unit = "km", dist=50, model = "WGS84", st.dist = 0.025, st.size = 3, x.min = bbox_ch[1], x.max = bbox_ch[3]-0.2, y.min = bbox_ch[2]+0.15, y.max = bbox_ch[4], border.size = 0.5)

europe <- c(left = -12, bottom = 35, right = 30, top = 63) %>% as.vector() %>% +0.01

europe_overview <- get_stamenmap( bbox = europe, maptype = "toner-background", color="bw", zoom = 3)

europe_overview_map <- ggmap(europe_overview, darken = c(0.6, "white"))+ coord_sf(default_crs = st_crs(4326))

fc <- sf::st_read("../data/fixed_online_data/BiogeographischeRegionen.gdb", layer = "N2020_Revision_BiogeoRegion")
fc <- st_transform(fc, 4326)
fc <- fc[fc$RegionNummer==2,] %>% st_union()

plot_path <- normalizePath(
  file.path(
    here(), "figures"
    )
  )
```

# Introduction

Prehistorians have long recognised demography as a fundamental force in human cultural evolution [@childe_man_1936]. Despite decades of interest in the population dynamics of prehistoric societies, concrete estimates of population size and density before written records remain elusive. Though the archaeological record provides multiple possible demographic proxies [@muller_tracing_2019], a lack of access to this data and methodological tools for turning it into quantitative estimates has left the conclusions drawn from it vague and superficial [@hassan_demographic_1981]. As a result, 'expert estimates' transferred from ethnographic parallels have often taken the place of direct inference from archaeological evidence [@morris_measure_2013; @turchin_seshat_2015].

Prehistoric demography has experienced a resurgence in interest in recent years [@shennan_population_2000; @riede_climate_2009 and others in same issue], partly explained by a renewed interest in human–environment relations and human impact, necessarily requiring an assessment of population size. Kintigh et al. [-@kintigh_grand_2014] list human influence, dominance, population size, and population growth amongst their 'grand challenges' for archaeology in the 21st century.

In particular, the 'dates as data' technique [@rick_dates_1987], using the frequency of radiocarbon dates as a proxy for population dynamics, has been significantly developed in the last decade [e.g. @shennan_regional_2013] and widely applied to archaeological contexts worldwide [@crema_review_2022]. This approach has contributed greatly to our understanding of prehistoric demography, but is not without its critics [@attenbrow_hiscock_2015; @carleton_groucutt_2020; @price_end__end_2021]. While the methodology continues to evolve and address these critiques [@crema_review_2022], it remains subject to fundamental problems common to all approaches relying on a single proxy [@french_manifesto_2021; @schmidt_approaching_2021]. We believe that these problems cannot be overcome by methodological refinements in this area alone. Instead, a Bayesian approach offers a robust, quantitative methodology for inferring prehistoric population dynamics from multiple proxies, including summed radiocarbon dates.

In the following article we present our methodology and demonstrate its application with a case study in the area north of the Swiss Alps. We use a type of Bayesian Generalised Linear Model [@kruschke2015] to combine the different proxies. Their assessment (weight and credibility intervals) results from the modelling and the combination of the data itself and is not defined a priori. Furthermore, we pursue the concept of a state space model [@auger-methe_guide_2021], a time series model in which a time series is interpreted as the result of a noisy observation of a stochastic process. In this sense, it is not a deductive model for testing a hypothesis, but a reconstructive (abductive) one, such it is also used in environmental reconstructions [@inkpen_explaining_2009]. In this respect, we hope to convince the readers that such an approach is far better suited to realising reliable reconstructions of past population developments than any of the previous approaches.

# Background

## Population estimation in prehistory

Proxies currently used for the estimation of population size in prehistory [following @muller_tracing_2019] can roughly be divided into three groups: ethnographic analogies; deductive estimates from ecological/economic factors; and the interpolation of frequencies of archaeological features (e.g. settlements, structures, individual finds). Three basic problems are common to all these approaches:

1.  **Reliance on single proxy**: Most investigations use only one source of evidence. Although multi-proxy approaches exist, the individual proxies only serve to support each other or the main estimator, without explicitly combining them.
2.  **Uncertainty in measurements**: All archaeological evidence is inherently uncertain which is carried through to derived measurements. However, in most studies, single curves are presented as estimates, and the potential error associated is almost never specified. 
3.  **Lack of a transfer function**: By 'transfer function', we mean something that allows for the proxy data to be interpreted in terms of actual population size or density. This could be absolute, i.e. a numerical estimate of population, or relative, i.e. a means of scaling changes in the proxy value to changes in population. Lack of suitable frameworks and 'calibration' data means that this is rarely presented alongside proxy estimates. In the best cases, there is a qualitative assessment of the informative value of the proxy, not sufficiently accounting for the complex nature of archaeological data.

Furthermore, the types of archaeological data commonly used as population proxies share a number of problematic characteristics, being:

-   **Limited**: We have only incomplete data, and it is usually not very informative.
-   **Unevenly distributed**: For example, although there is a good data on settlement frequencies for some regions, these regions are very unevenly distributed over time and space.
-   **Noisy**: Frequently individual proxies are strongly influenced by factors unrelated to population, for example taphonomic conditions or depositional biases.
-   **Unreliable**: Research strategies, research history and varying levels of resources available to researchers strongly affect the nature of compiled datasets. Systematic distortions are the rule rather than the exception.
-   **Heterogeneous**: All potential proxies have different spatio-temporal scales, granularity, information value, scales, and data formats.
-   **Indirect**: We will never have direct data on prehistoric population; only proxy data that is thought to be a reasonable substitute. The transfer functions linking the proxy data with the desired quantity (population) are unknown.
-   **Contradictory**: When considering several proxies, differences in transfer functions, data quality and noisiness inevitably lead to different results.

Many, if not all, of these problems can be ameliorated through a) the explicit, quantitative integration of multiple proxies; and b) the use of a Bayesian approach to take account of and estimate uncertainty.

## Hierarchical Bayesian demographic models

Many of the problems with archaeological population proxies are shared with contemporary demography. In response, demographers have increasingly turned to Bayesian methods to estimate and forecast contemporary population dynamics. For example, Bryant and Zhang [-@bryant2018] consider Bayesian data modelling a solution to exactly the kind of problems that affect archaeological data. Bayesian approaches are well suited for limited, unreliable and noisy data. Various data sources, even contradictory data, can be brought into a common framework and used to support one another. These methods also provide a quantitative estimate of the likelihood and uncertainty of the model's resulting predictions (or in our case retro-dictions). Bayesian approaches are also capable of accounting for spatially and temporally incomplete data: where this data is missing, the uncertainty increases, but this does not prevent general modelling and estimation. Finally, hierarchically-structured model suites, with sub-models for each individual proxy, can be used to estimate transfer functions between them and the value to be modelled, thanks to the interaction of a large number of evidence.

This modeling technique can thus be used to join different lines of evidence horizontally and vertically and combine their results into a overall estimate, including an assessment of their reliability: contradicting data lead to a lower overall reliability, while a mutual support to smaller confidence intervals. If there is no systematic bias that affects all data sources to the same extent, this results in the most reliable estimate possible through the most heterogeneous set of data sources.

Bayesian radiocarbon calibration is a similar, well-established application in archaeology, where radiometric uncertainty is modelled based on prior stratigraphic information. More recently, archaeologists have also used Bayesian modelling techniques for testing hypotheses relating to demographic models based on ^14^C data [e.g. @crema2021a]. This approach differs from the one presented here in that, in these analyses, deductive models are generated and their plausibility is tested on the basis of ^14^C data only. This is a clear step forward to a model-based, scientific analysis. However, the use of only one proxy, exclusively for testing hypotheses developed independently, creates problems comparable to those of the inductive approaches used so far: lacking a combination with other indicators, one is limited to the problems and conditions of sum calibration. Furthermore, this approach loses significant potential information that would be gained by a direct evaluation of time series.

We attempt to make Bayesian hierarchical techniques usable for archaeological reconstructions. We want to show, in a reproducible and practical form using a case study, how Bayesian methods can make a decisive contribution to a better assessment of population development, crucial for the reconstruction of the human past, even in for periods for which we only have very patchy, noisy and unreliable data.

## The Bayesian approach

Bayesian statistics relies on the premise that there is always some prior assumption, even if very rough, about the probability of an event. This assumption is adjusted by observing data, by checking how credible these priors are [likelihood, see also @bryant2018, 66]. This is Bayesian updating [cf. also @kruschke2015, especially 15--25], resulting in the posterior probability distribution, which represents not a point prediction. Small amounts of data lead to a broad distribution not strongly localised and restricted. Thus, we simultaneously obtained a result and an estimate the credibility interval, given the data.

This Bayesian learning is iterative and sequential, so that the result of one Bayesian inference can form the prior of another [@kruschke2015, 17]. This allows different information to be combined [@bryant2018, 219--224], as it has long been exploited by archaeology in using stratigraphic information to make radiometric dating more accurate [@ramsey1995].

This also makes a hierarchical formulation of problem domains possible. Parameters that are necessary for an estimation, such as the relationship of population density to the deforestation signal in pollen data, need not be specified explicitly, but can be given by probability distributions and then estimated in the model itself [@bryant2018, 186]. The more data available, the more degrees of freedom can be estimated with a reasonable width of credibility intervals [@kruschke2015, 112]. For the estimation of these parameters, submodels have to be created describing the relationship of the data to the characteristics of the parameter [@kruschke2015, 221--222].

# Materials: population proxy data

Our case study area north of the Swiss Alps (Figure \@ref(fig:mapswissplateau)) covers about one third of Switzerland’s territory and comprises the partly flat, but largely hilly area between the Jura Mountains and the Alps. It is favourable for settlement and agriculture; the Swiss Plateau between Lake Zurich and Lake Geneva is by far the most densely populated region of the Switzerland today. This serves as our core region of interest because it is here that archaeological data is most abundant and accessible. The region has a very diverse natural landscape: shaped by glaciers during the ice ages, the many lakes and bogs provide excellent preservation conditions for the numerous Neolithic and Bronze Age lakeside settlements, and a rich source for vegetation reconstructions by means of pollen analyses. Thanks to very active and efficient archaeological research and heritage management there is an abundance of archaeological information, including known sites as well as dendrochronological and ^14^C data.

```{r mapswissplateau, fig.cap="Location and extent of the Swiss Plateau as biogeographical region (based on swisstopo) including additional low altitude areas in the north of Switzerland (regions along the High Rhine between Schaffhausen and Basel)."}
main_map <- my_basemap +
  geom_sf(data = fc, inherit.aes = FALSE, alpha = 0.33, fill="darkred", color=NA) +
  blank() +
  my_scalebar

inset_map <- europe_overview_map +
  geom_sf(data = switzerland_bb, fill = NA, color = "darkred", inherit.aes = FALSE) +
  blank()

ggdraw() +
  draw_plot(main_map) +
  draw_plot(inset_map, x = 0, y = 0.7, width = 0.3, height = 0.3)
```

Our case study targets the period between 6000–1000 BCE. The lower limit of this time window was chosen to avoid the so-called 'Hallstatt plateau' in the Northern Hemisphere radiocarbon calibration curve, which causes difficulties for the ^14^C proxy. The upper limit coincides with post-glacial changes in pollen spectra, before which the openness indicator is highly unlikely to reflect human influence.

A large number of different proxies can be integrated into a model of this type, provided that these observations a) can be understood as dependent on the population density in the past, and b) a model-like description of this dependence can be created. Table \@ref(tab:tableproxies) provides a non-exhaustive list. For our case study, we used a landscape openness indicator; an aoristic sum of typological dated sites; a sum calibration; and frequency data for dendro-dated lakeshore settlements in the Three Lakes region (western Swiss Plateau).

| Proxies                                        |
|------------------------------------------------|
| Expert estimates                           |
| Ethnographic Analogies                         |
| Carrying Capacity                              |
| Economic modelling                             |
| Extrapolation of buried individuals            |
| Burial anthropology                            |
| Settlement data, number of houses              |
| Settlement data, settlement size               |
| **Aoristic analysis**                          |
| **Dendro dates**                               |
| Amount of archaeological objects               |
| **Radiocarbon sum calibration**                |
| Estimates based on specific object types       |
| **Human impact from pollen or colluvial data** |
| aDNA based estimates                           |
| ...                                            |

: (#tab:tableproxies) An incomplete list of possible observation that can be linked to population developments in the past. Proxies used in this study are highlighted.

For all proxies used, it is a common assumption that they are positively correlated with past population levels. In some cases we have reprocessed them in this respect in order to emphasise this relationship even more strongly in our opinion (example: pollen data). This is of course a strong assumption, but we believe it is justified, as this has been widely accepted in the scientific literature, and these proxies are used accordingly (each in isolation). Our ambition with this article is to present an abductive model to help improve the current practice of proxy use. Our ambition is not to justify or verify the use of these proxies itself. This can only be done through empirical, hypothesis-testing approaches with known response observations. What our method can do, however, is to infer, through a weighting resulting from the modelling, which indicators seem to be better suited in terms of their variability and fit with other indicators to trace a population development in the past.

## Dendro-dated lakeshore settlements

From the Neolithic onwards, known settlement areas in Switzerland concentrate along its rivers and lakes [@christianlüthi2009]. Thus, our working region offers excellent data for demographic estimation, but poses very specific problems for such an undertaking. We have high-resolution information on the temporal sequence of individual lakeside settlements by means of dendro data. In these cases, ^14^C data are not as abundant simply because they are inferior to dendro dating.

```{r echo=FALSE}
dendro <- read.csv(file.path(rstudioapi::getActiveProject(), "data", "raw_data", "dendro_years.csv"))
```

The dataset we use for the number of dendro-dated wetland settlements in the Three Lakes region was collected by Julian Laabs for his PhD thesis [@laabs2019]. The time series used here runs from `r abs(min(dendro$date))` to `r abs(max(dendro$date))` BCE, and contains the number of chronologically registered fell phases at individual settlements.

## Summed radiocarbon

Summing up the probabilities of radiocarbon dates can undoubtedly be considered the standard approach in demographic reconstruction in archaeology today. The logic for this can be derived from the Poisson binomial distribution: such a distribution can be described as the sum of independent Bernoulli trials as it represents the probability estimate for the existence or use of a site per unit time. The expected value per time unit for the number of simultaneously existing sites/settlements is the sum of the individual probabilities for the sites, i.e. the area under the curve of the probabilities of 14C data. Incidentally, the same logic applies to the aoristic sum (shown below). The main problem with this proxy is therefore not so much its statistical nature, but mainly the systematic biases that arise from the conservation and finding practicalities in the research process. To counter these, and to detect and mitigate the systematic biases, hierarchical modelling such as that carried out in this study is appropriate.

```{r echo=FALSE}
c14 <- read.csv(file.path(rstudioapi::getActiveProject(), "data", "raw_data", "14c_swiss_plateau.csv"))
```

The dataset for the ^14^C sum calibration primarily consists of data from the XRONOS database (https://xronos.ch), supplemented by dates from the unpublished PhD thesis of Julian Laabs [@laabs2019] and the data collection of Martínez-Grau et al. [-@martínez-grau2021]. It contains a total of `r nrow(c14)` single ^14^C data from `r length(unique(c14$site))` sites (see Figure \@ref(fig:c14map)). The dates in the dataset range in ^14^C years from `r max(c14$bp)` to `r min(c14$bp)` uncal BP. This time window extends beyond the study horizon in order to minimise boundary effects. 

We binned the data at site levels to obtain a temporally dispersed count and thus an expected value of contemporaneous ^14^C dated sites. For the creation of the sum calibration, the corresponding functions of the R package rcarbon [@crema2021] were used with their default settings.

```{r c14map, fig.cap="The location of the ^14^C dated sites in the dataset."}
my_basemap + geom_point(data = c14, aes(x = lng, y = lat), color = "darkred", alpha = 0.75) + blank() + my_scalebar
```

## Aoristic sum

```{r echo=FALSE}
aorist <- read.csv(file.path(rstudioapi::getActiveProject(), "data", "raw_data", "site_data_fuzzy.csv"))
aorist_latlng_coords <- st_as_sf(aorist,coords = c("LV03_Rechtswert_fuzzy", "LV03_Hochwert_fuzzy"),crs = 21781) %>% sf::st_transform(
  4326
) %>% st_coordinates() %>% as.data.frame()
```


```{r aoristmap, fig.cap="Location of the sites from the find reports of cantonal archaeology (heritage management) authorities. Locations are 'fuzzed' by approximately 1 km."}
my_basemap + geom_point(data = aorist_latlng_coords, aes(x = X, y = Y), color = "black", alpha = 0.75) + blank() + my_scalebar
```

We include relative dating information obtained from the heritage authorities of the Swiss cantons (Figure \@ref(fig:aoristmap)). These are primarily derived from scattered surface finds, often with a low dating accuracy (only in the range of archaeological periods), incorporated into our model as a typologically-dated, aorist time series. However, it is not dependent on radiocarbon dating and thus it avoids the methodological issues of sum calibration. Data from `r nrow(aorist)` sites were included in the aoristic sum.

```{r aoristcurve, fig.cap="Aoristic sum of archaeological sites used in the analysis."}
joined_data <- read.csv(file.path(rstudioapi::getActiveProject(), "data", "preprocessed_data", "all_proxies.csv"))
ggplot(joined_data) + geom_line(aes(x=(1950-age)*-1, y=aoristic_sum, color = "darkgray"), alpha = 0.75) +
  theme_minimal()  +  scale_x_reverse() +
    labs(x = "years BCE",
         y = "aoristic sum",
         color = "Legend") + 
    scale_color_manual(values = "darkgray", labels = "Aoristic Sum")+
  theme(legend.position="bottom")
```

## Landscape openness 

Natural conditions in the Swiss lakes enable not only highly precise dating of archaeological sites, but also a very dense network of pollen analysis. We make use of this by generating a supra-regional openness indicator for the vegetation from the pollen data (Figure \@ref(fig:pollensites)). This proxy has the specific advantage that it is not dependent on archaeological preservation conditions, making it particularly valuable for compensating systematic distortions that result from archaeological taphonomy and period-specific settlement patterns.

```{r pollensites, fig.cap="Location of the pollen profiles used for the openness indicator."}
pollen_sites <- read.csv(file.path(rstudioapi::getActiveProject(), "data", "raw_data", "pollen_locations.csv"))

my_basemap +
  geom_point(data = pollen_sites, aes(x = lng, y = lat), color = "darkgreen", alpha = 0.75) + blank() +
  geom_text_repel(data = pollen_sites, aes(x = lng, y = lat, label = name), alpha = 0.75, nudge_x = 0.2, nudge_y=0.02) +
  my_scalebar
```

We assume that the higher the population density in an area, the greater the human influence on the natural environment [@zimmermann2004; @lechterbeck2014]. Evidence of deforestation can therefore provide indications of population dynamics. The full procedure for deriving this proxy from several different pollen diagrams is detailed in a previous publication [@heitz2021]. Here, we use five pollen diagrams from sites mainly in the hinterland of the large Alpine lakes.

```{r pollenproxy, fig.cap="Value on the first dimension of the PCA against dating of the samples for the individual pollen profiles and their combined average value as the openness indicator."}
knitr::include_graphics(file.path(rstudioapi::getActiveProject(), "figures", "pollenproxy.pdf"))
```

# Methods: Bayesian model

Sum calibration, openness and the dendro-dated settlement data was smoothed by a moving average with a 50 years window, corresponding to the unified sampling interval for all proxies. The aoristic sum was not smoothed, because it already has a very coarse temporal resolution. In the construction of our 'observational model', we considered all these proxies as informative of the number of settlements located in the north of the Swiss Alps. Population development is simulated in a 'process model' using a Poisson process.

## Process model

A special class of Bayesian hierarchical models are so-called 'state space models', specifically designed for time series. They follow two principles. First, a hidden or latent process is assumed, representing the state of the variable of interest $x_t$ through the entire time series. Every state of variable x in the future, as well as in the past, is bound by a Markov process to the state of variable $x$ at time $t$. Second, it is assumed that certain observations, represented in variable y, are dependent on the state of variable $x$ at time $t$. This implies that a relationship between the individual states of variable $y$ is generated over time via the hidden variable $x$, which is not directly observable.

This structure makes these models particularly suitable for demographic reconstruction using archaeological and other data. Population density itself is not directly measurable: all we have at our disposal are observations derived by unknown transfer functions.

Our overall model is broken down into several hierarchically-connected individual elements. The process model represents the demographic development itself, without already being explicitly parameterised with data. Here we assume that the latent variable 'number of sites' is strongly autocorrelated across different time periods. The number of sites in 3000 BCE is strongly conditioned by the number of sites in 3050 BCE, and so on. The population at time $t$ results from the population at time $t-1$ times a parameter $\lambda$, which represents the population change at this time.

$$
N_t = N_{t-1} * \lambda_t
$$

A univariate discrete Poisson distribution is particularly suitable for modelling frequencies, numbers of events that occur independently of each other at a constant mean rate in a fixed time interval or spatial area. It is determined by a real parameter $\lambda$ \>0, describing the expected value and the variance. Thus, the relationship shown above can be rearranged as follows:

$$
\begin{aligned}
N_t &\sim dpois(\lambda_t) \\
\lambda_t &= N_t
\end{aligned}
$$ 

If we now have information about the change in population development (the proxies), this can enter into the model via a change in $\lambda$ in form of a regression: for all proxy values — represented as a vector of independent variables $x \in R^n$, with $R^n$ as an n-dimensional Euclidean space defined by the n variables — the model takes the form:


$$
log({E} (Y\mid x))=\alpha + \beta' x
$$

Using the logarithm as a link function ensures that $\lambda$, which must always be positive, can also be described by variables that may also be negative. $\beta$ serves as slope factor, as in a normal linear regression. Here, it functions as a scaling factor for the individual proxies. $\alpha$ is to be understood as an intercept, representing a baseline when there were no change due to the variables. This is the desired behaviour: $\lambda$ is equal to the value of the population in the previous time period, plus or minus the changes resulting from the variables.

$$
log(\lambda_t) = log(N_{t-1}) + \sum_{i=1}^n \beta_i x_{t,i}
$$

Since $\lambda$ and $N$ are essentially in the same range (e.g. if $lambda=1$, the expected value for $N$ would also be 1), $N_{t-1}$ must also be log-transformed for the congruence of both values. Population size $N_t$ as well as population change $\lambda_t$ are time-dependent. At each individual point in time, these variables will take on different values. But we can assume that the population change will not exceed certain limits ($max\_change\_rate$), though it is not possible to specify this at this point.

$$
\begin{aligned}
max\_growth\_rate &\sim dgamma(shape = 5, scale=0.05) \\
N_t/N_{t-1} &< (max\_growth\_rate + 1) \\
N_{t-1}/N_t &< (max\_growth\_rate + 1)
\end{aligned}
$$

A gamma distribution centres probability in the range $[0,1[$; adding 1 makes this range $[1-2[$. This prevents the number of sites from explosively increasing between two time periods, which would lead to problems for the convergence of the model. The estimation of this parameter for the entire model, as well as the estimation of the respective population change per time section, results from the modelling and the interaction with the data.

## Observational model

In this initial implementation, the observational model is essentially a Poisson regression, where the proxies are used to inform the change in the number of settlements between time steps. The individual proxies were z-normalised and absolute differences between time steps were then computed. If the value of the proxy increases, this results in a positive difference from the previous time step, and vice versa.

$$
\begin{aligned}
z_t &= \frac{x_t - \bar{x}} {\sigma_x}\ |\ \sigma_x := Standard\ Deviation  \\
\delta z{_t} &= z_t - z_{t-1}
\end{aligned}
$$

The sum of the resulting differences between the time steps, together with the settlement number of the previous step as the expected value, then forms $\lambda_t$: the expected value for the settlement number of the current time step.

$$
log(\lambda_t) = log(N_{t-1}) + \sum_{i=1}^n \beta_i \delta z_{i, t}
$$

Here, $\beta_i$ is a scaling factor that represents the influence of the respective proxy. It is a confidence value of the model for the respective proxy, so that the sum of all $\beta_i$ results in 1.

$$
\sum_{i=1}^n \beta_i = 1
$$

A Dirichlet distribution—a multivariate generalization of the beta distribution—is commonly used for this purpose in hierarchical Bayesian modelling. Its density function gives the probabilities of $i$ different exclusive events. It has a parameter vector $\alpha = (\alpha_1, ..., \alpha_i)\ |\ (\alpha_1, ..., \alpha_i) > 0$, for which we have chosen a weakly informative log-normal prior. The priors for the log-normal distribution in turn come from a weakly informative exponential distribution for the mean and a log-nomal distribution with $\mu$ of 1 and $\sigma_{log}$ of 0.1:

$$
\begin{aligned}
\beta_i &\sim Dir(\alpha_{1-i}) \\
\alpha_i &\sim LogNormal(\mu_{alpha_i}, \sigma_{alpha_i}) \\
\mu_{alpha_i} &\sim Exp(1) \\
\sigma_{alpha_i} &\sim LogNormal(1,0.1)
\end{aligned}
$$

Intuitively, we consider the sum of the proxies as determinant of the number of settlements. That is, the share of each individual proxy is variable and is estimated within the model. This share is recorded within the model as the parameter p.

The error value is represented by the Poisson process in the process model. In this implementation, the model finds the best possible combination between the individual proxies to describe a settlement dynamic. The number of sites is converted into population density using (certainly debatable) parameters defined by us, but which are only scaling factors for the intermediate value of number of settlements. We assume that each site represents a number of people that is poisson distributed around the value 50, a compromise, as both Mesolithic and Neolithic and Bronze Age settlement communities need to be represented. An evidence-based estimate data series of the temporal development of settlement sizes could enhance this specification. From the number of sites and the mean number of individuals a population density can be calculated using the case study area (12649 km²), making the models estimate comparable with estimates from other sources or the literature.

```{r expertestimations, fig.cap="Expert estimate of population density on the Swiss Plateau."}
expert_estimations <- read.csv(file.path(rstudioapi::getActiveProject(), "data", "raw_data", "estimates.csv"))

ggplot(expert_estimations) + geom_segment(aes(x=from * -1, xend = to * -1, y = estimate, yend = estimate, color = source)) + xlab("cal BCE") + ylab("Density p/km²") + theme_minimal() + scale_x_reverse()
```

## Model fitting

The model was fitted using the R package *nimble* (version 0.11.1, R version 4.1.3), using 4 parallel chains. Achieving and ensuring convergence and sufficient effective samples (10000) for a reliable assessment of the highest posterior density interval was carried out in steps.

1) the model was initialised for each chain and run for 100000 iterations (with a thinning of 10). On a reasonably capable computer (Linux, Intel(R) Xeon(R) CPU E3-1240 v5 \@ 3.50GHz, 4 cores, 8 threads), this takes approximately a minute.

2) the run was extended until convergence could be determined using Gelman and Rubin's convergence diagnostic, the criterion being that a potential scale reduction factor of less than 1.1 was achieved for all monitored variables. Convergence occurred after about thirty seconds.

3) Due to the high correlation of the parameters and thus a low sampling efficiency, the collection of at least 10,000 effective samples for all parameters took about five hours.

A starting value of 5 p/km² for the population density of the Late Bronze Age (1000 BCE) was taken from the literature, which may represent a general average value for all prehistoric population estimates [@nikulka2016, 258]. For the model, this was set as the mean of a normal distribution with a standard deviation of 0.5, which should give enough leeway for deviations resulting from the data. Nevertheless, it should be noted that our resulting estimate is strongly conditioned by this predefined value, especially in the later sections.

For traceplots and the prior-posterior overlap, as well as density functions of the posterior samples of the individual parameters, please refer to the supplementary material.

```{r, results='hide'}
x <- 1:100
```

```{r dpois50, results='hide'}
pdf(file = file.path(plot_path, "dpois50.pdf"), width = 2, height = 2)
oldmar <- par(mar = c(2, 2, 2, 2))
plot(x,dpois(x,50), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
par(oldmar)
dev.off()
```

```{r dgammamaxgrowthrate, results='hide'}
pdf(file = file.path(plot_path, "dgammamaxgrowthrate.pdf"), width = 2, height = 2)
oldmar <- par(mar = c(2, 2, 2, 2))
plot(x/50+1,dgamma(x/50,shape = 5, scale = 0.05), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
par(oldmar)
dev.off()
```

```{r mualpha, results='hide'}
pdf(file = file.path(plot_path, "mualpha.pdf"), width = 2, height = 2)
oldmar <- par(mar = c(2, 2, 2, 2))
plot(x/20,dlnorm(x/20,1,0.1), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
par(oldmar)
dev.off()
```

```{r aalpha, results='hide'}
pdf(file = file.path(plot_path, "aalpha.pdf"), width = 2, height = 2)
oldmar <- par(mar = c(2, 2, 2, 2))
plot(x/10,dexp(x/10,1), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
par(oldmar)
dev.off()
```

```{r alpha, cache=TRUE, results='hide'}
n_sample <- 1000000
mu_a <- rlnorm(n_sample,1,0.1)
a_a <- rexp(n_sample,1)
alpha <- rlnorm(n_sample,mu_a,a_a)
pdf(file = file.path(plot_path, "alpha.pdf"), width = 2, height = 2)
oldmar <- par(mar = c(2, 2, 2, 2))
plot(density(alpha, from=0,to=100), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
par(oldmar)
dev.off()
```

```{r p, cache=TRUE, results='hide'}
p <- matrix(nrow = 10000, ncol = 4)
for (i in 1:nrow(p)) {
 p[i,] <- nimble::rdirch(1, sample(alpha,4))
}
pdf(file = file.path(plot_path, "p.pdf"), width = 2.5, height = 2.5)
oldmar <- par(mar = c(2, 2, 2, 2))
par(mfrow=c(2,2))
plot(density(p[,1]), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
plot(density(p[,2]), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
plot(density(p[,3]), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
plot(density(p[,4]), type="l", ann = FALSE, axes = FALSE, lwd=4, col = "skyblue");axis(1)
par(oldmar)
par(mfrow=c(1,1))
dev.off()
```

| **Priors**           | **Value**                            | **Plot/Comment**                                                               |
|-----------------------------|--------------------------|-----------------|
| MeanSiteSize         | dpois(50)                            | ![MeanSiteSize](../figures/dpois50.pdf)                |
| max_growth_rate      | dgamma(shape = 5, scale=0.05) + 1    | ![max_growth_rate](../figures/dgammamaxgrowthrate.pdf) |
| mu_alpha             | dlnorm(1,sdlog=0.1)                  | ![mu_alpha](../figures/mualpha.pdf)                    |
| a_alpha              | dexp(1)                              | ![a_alpha](../figures/aalpha.pdf)                      |
| alpha                | dlnorm(mu_alpha[j],sdlog=a_alpha[j]) | ![alpha](../figures/alpha.pdf)                         |
| p                    | ddirch(alpha[1:4])                   | ![p](../figures/p.pdf)                                 |
| **Parameters**       |                                      |                                                                                |
| nEnd                 | 5                                    |                                                                                |
| AreaSwissPlateau     | 12649 km²                            |                                                                                |
| **Initial Values**   |                                      |                                                                                |
| lambda$_{1:nYears}$  | $log(1-10^{\frac{1}{nYears-1}})$     | exponential increase of the factor 10                                          |
| PopDens$_{1:nYears}$ | nEnd (=5)                            |                                                                                |
| nSites$_{1:nYears}$  | 50                                   |                                                                                |

: (#tab:priorsandparameters) Priors and fixed parameters used in the model.

# Results

```{r popdensplot, fig.cap="Estimate of population density predicted by the model. The four input proxies are also plotted (scaled) for comparison."}
knitr::include_graphics(file.path(rstudioapi::getActiveProject(), "figures", "popdens_estimation.pdf"))
```

The population density estimated by the model (Figure \@ref(fig:popdensplot)) ranges between 0.2 p/km² for the beginning (6000 BCE) and 4.8 p/km² for the end of the estimate (1000 BCE), reaching a maximum of 6.5 p/km² for around 1250 BCE. This remains within the range considered plausible according to expert estimates. There are clear peaks around 1250 BCE and around 2750 BCE, which corresponds to the beginning of the influence of Corded Ware ceramic styles [@hafner_vom_2004].

```{r varcoeffplot, fig.cap="Variability of the model estimate of population density over time, with the estimate itself for reference."}
knitr::include_graphics(file.path(rstudioapi::getActiveProject(), "figures", "popvar_plot.pdf"))
```

The temporal distribution of variability in the estimate (Figure \@ref(fig:varcoeffplot)) allows us assess at which time steps the uncertainty is greater due to e.g. contradictions in the proxies. The coefficient of variation is 0.13 for the beginning and 0.1 for the end of the estimate, with the greatest variability (0.47) seen around 2150 BCE. This is not surprising as there are fewer archaeological contexts recorded from the earlier phase of the Early Bronze Age, c. 2200-1800 BCE. This picture changes from c. 1800 BCE onwards [@hafner_fruhe_1995; @david_elbiali_suisse_2000]. The beginning and end of the time series are relatively clearly determined, resulting from the *a priori* setting of final population density, but also from the uniformity of the proxies during these periods. Overall, the variability is relatively stable over the entire estimation and averages 33% of the respective mean.

```{r pdistribution, fig.cap="Distribution of influence ratios of proxies on model's final estimation of number of sites."}
knitr::include_graphics(file.path(rstudioapi::getActiveProject(), "figures", "p_estimation.pdf"))
```

The parameter $p$ reflects the relative weight given to the individual proxies. Its posterior distribution (Figure \@ref(fig:pdistribution)) shows that the model weights the openness indicator the highest, averaging slightly above 60%, followed by the sum calibration, with an average of about 20%. The aoristic sum is slightly above 10%, whereas the importance of the dendro-dated settlements is below 10%. The reason for the latter is certainly that there are no lakeshore settlements over large areas of the time window, and therefore the overall confidence in the proxy is low. The aoristic sum is flat for long periods, making it difficult to integrate with other proxies. The sum calibration shows very strong short-term fluctuations, at least partly due to the calibration curve, which suggests that it does not reliably represent a continuous population trend. Its fluctuations have an impact on the model's estimate, albeit to a lesser extent than the general trend.

# Discussion

## Reliability of the overall estimation

We consider each of the proxies used to be intrisically flawed and biased. Therefore, we assume that none of them alone is suitable to generate a population estimate with sufficient credibility. Especially since the use of a single proxy makes it impossible to specify a confidence interval, as its value must be used as a direct indication of a change in population size.

Rather, we assume that all proxies used are influenced, to a greater or lesser extent, by a proportion of random noise as well as by one of the actual signal. As long as there is no ground truth that can be used for calibration, this cannot be fully differentiated. What we assume, however, is that the noise between the individual proxies is uncorrelated, but the signal must essentially produce a coherent pattern.

However, other reasons are also conceivable. For example, a correlation between two parameters can also be caused by the fact that they are affected by the same confounding influence. All archaeologically derived proxies are subject to preservation conditions. If no signs of human activity are preserved for a certain space at a certain time based on the surviving archaeological evidence, then all these indicators will also show a settlement gap. It is therefore all the more important to use independent proxies that are not affected by the same distorting influences for a robust reconstruction. This is the reason why the openness indicator is an essential part of this study, as it is not confounded by the archaeological record. Other similarly independent indicators are to be integrated in future applications of our approach to make the result even more robust.

Moreover, our modelling approach in terms of an abductive reconstructive model is also such that in its present form the model provides the best possible summary of the proxies used and thus the best possible reconstruction given the available information. It must be emphasised that such a model does not attempt to directly represent the process of the relationship between proxy and latent variable. We treat all proxies as equal (false), and leave it to coherence with respect to the underlying process (the latent population development) to provide a weighting. In our view, this corresponds to a (pragmatic) implementation of the general scientific process. However, this also means that we prefer a useful model to a less useful one without wanting to (or being able to) make a statement about the concept of truth of a model.Especially in comparison to the uncritical application of a purely radiocarbon data-based proxy, as it is currently used in large scale, we see the significance of such a model and the philosophy behind it as more than justified.

## Reliability of individual proxies

Comparing the model's overall estimate with the individual proxies provides several insights into the quality of these records. The sum calibration, currently the most frequently used proxy for (relative) population change in prehistory, has its large fluctuations dampened when considered alongside other proxies. This is especially ture of the first fluctuation shortly after 4000 BCE. The expected increase in archaeological remains with the onset of Neolithisation is still clearly visible, but the overall curve is much flatter than the sum calibration itself. The period between 3950 and 3700 BCE, contemporaneous with the first major settlement of the Three Lakes regions' lakeshores, coincides with a noticeable plateau in the calibration curve, producing an overestimation of the ^14^C density. A second maximum, after 3000 BCE, is supported by the other proxies, and is consequently much more reflected in the overall estimate, coinciding with a smaller and shorter plateau. The rise towards the Middle and Late Bronze Age is also supported by the other proxies, without a significant pattern in the calibration curve. We may conclude that the model is successful in using information from other proxies to sift 'real' fluctuations in the summed radiocarbon record from artefacts of the calibration curve.

On average, the model weights the sum calibration at about 20%, significantly less than the 60% afforded to the openness indicator. After an initial increase, which is easily explained by spread of agriculture, the openness indicator tends to fluctuate less and thus has a dampening effect on the overall estimate. In general, this trend in the sum calibration is well reflected in land openness, while changes within the Neolithic and Bronze Age are more gradual.

The aoristic sum remains flat over long spans of time. It is not until the Middle and Late Bronze Age that we see a significant rise, which is also apparent in the model's overall estimate. It remains to be seen to what extent modelling of the taphonomic loss [@surovell2009] could be integrated in this approach.

The number of simultaneously existing lakeshore settlements is a temporally and spatially limited estimator, but extremely reliable. Its limitations are reflected in the low overall confidence of the model, since its value is zero over long stretches. However, where it has information potential, such as around and shortly after 3800 BCE, 3200 BCE, 1600 BCE or especially around 2750 BCE, its fluctuations have a noticeable influence on the overall estimate. This highlights another potential of our approach: where a proxy has little structure and thus little significance, or where its trends cannot be linked to other indicators, it consequently has little influence. For periods in which it can provide information, however, this will also feed into the overall model, despite a low overall confidence in the estimator.

## Prehistoric population dynamics north of the Swiss Alps

In order to review the reconstruction against the background of established archaeological knowledge, it is useful to overlay conventionally-defined archaeological phase boundaries [@hafner_neolithikum_2005] on the results of our model (Figure \@ref(fig:popestwithphases)).

```{r popestwithphases, fig.cap="Estimate of population density in relation to the established chronology of the case study area north of the Swiss Alps."}
PopDens_summary <- read.csv(
  file = normalizePath(
            file.path(here(), "data","preprocessed_data", "popdens_summary.csv"
                      )
            )
  )

chronology <- read.csv(
  file = normalizePath(
            file.path(here(), "data","raw_data", "chrono_rough_de.csv"
                      )
            ), row.names = 1
  )
chronology <- chronology[order(chronology$dat_begin),]
chronology$label <- factor(chronology$label, levels = chronology$label)

ggplot(PopDens_summary) +
  geom_line(aes(x = (1950-age)*-1, y = mean)) + 
  geom_line(aes(x = (1950-age)*-1, y = hpdi_l), lty=2) + 
  geom_line(aes(x = (1950-age)*-1, y = hpdi_u), lty=2) + 
    theme_minimal() + scale_x_reverse() +  
ylab("P/km²") +
  xlab("cal BCE") +
  geom_rect(data=chronology[-1,],aes(xmin=dat_begin*-1,ymin=0,xmax=dat_end*-1,ymax=Inf,fill=label),
                    alpha=0.5,inherit.aes=FALSE) +
    scale_fill_brewer(palette="Pastel1", guide = "none") +
  geom_text(data=chronology[-1,],
            aes(x=(dat_end - 100)* -1,y = 0.25,label=label),
            alpha=0.25,inherit.aes=FALSE, angle = 90, hjust = 0)
```

The Early and Middle Neolithic are hardly documented in Switzerland. We must assume a low level of settlement, probably mainly by mobile groups. Isolated Neolithic sites of the LBK and later groups are known in the periphery of Switzerland, but they play a subordinate role [@ebersbach_nutzung_2012]. The evidence of the Neolithic is dense from the so-called Upper Neolithic onwards, connected with the typochronological pottery phases of Egolzwil (late 5th millennium BCE) and Cortaillod respectively Pfyn (first half of the 4th millennium BCE). The first lake shore settlements north of the Alps date to this time too. Here we see a clear increase in the estimated population in the model. In the transition to the Late Neolithic, we know from the lakeshore settlements the so-called Horgen Gap [@hafner_neolithikum_2005]. This is also visible as a slight decrease in the model. In another study [@heitz2021] we demonstrated that this is in fact probably not a decline in population. Rather communities relocated their settlements to the hinterland of the large lakes in times of stronger lake level rises due to climatic changes. In the Late Neolithic, associated with the Horgen pottery, we then see a clear increase in the settlement intensity, which peaks and breaks off at the transition to the Final Neolithic [@hafner_vom_2004]. In the second half of the Early Bronze Age, during which lakeshores were resettled to a smaller extend, there is again a clear increase in population size according to the model, continuing until the Late Bronze Age. The general trends fit very well with the previous reconstructions of population development for Switzerland [see eg. @lechterbeck2014], while offering higher precision and higher resolution.

# Conclusions

The key advance in the model we present is the ability to estimate, in absolute terms, past population sizes and the uncertainty accompanying our present knowledge. These estimates can be a basis for further studies where relative measures of population development are not helpful, such as long-term land use studies. Modelling of large-scale socio-ecological systems based on archaeological data does not have to rely deductive, asynchronous population models (e.g. carrying capacity or ethnographic analogues).

We have also demonstrated that, with Bayesian hierarchical modelling, it is possible to achieve a true multi-proxy analysis – as opposed to a juxtaposition of different indicators. This opens up the possibility of quantitatively linking different records and assessing their credibility. We are also able to specifying a confidence interval for the overall estimate. The result is a firmer basis for reconstructing population dynamics and settlement patterns in prehistory.

Nevertheless, we consider this model as only the first step towards a more sophisticated Bayesian approach. We have trusted the individual proxies in aggregate, without individualised measurement error. Our estimates are based on a limited number of sources, almost all of which are subject to taphonomic biases in the archaeological record. Consequently, we can only transform the model's prediction into an absolute estimate of population density with predefined parameters: settlement size and the initial value of the reconstruction. Overcoming this limitation would represent a major refinement of our approach. 

Incorporating additional proxies independent of the immediate, time-dependent conditions of the archaeological record could be one way to achieve this. These could be data on settlement sizes, parameters for economic-ecological carrying capacity, demographic data from burial groups or archaeogenetic data on population sizes. This data is available to varying degrees in different regions. On the Swiss Plateau, for example, we have little data on human remains over large spans of prehistory, in contrast to the abundance of wetland settlements.

To apply this approach to other regions, the proxies we use here would have to be adapted to fit local conditions and research histories. By means of large-scale modelling, however, it would be possible to supplement gaps in the data in one region with data from another by regionalisation and a partial transfer of information (partial pooling). Such an extension would be the next logical step in the improvement of the model, to which end we hope to be able to contribute a further study in the near future.

# Acknowledgements

Data collection were conducted as part of the project 'Beyond lake settlements' in the doctoral thesis of Julian Laabs, funded by the SNF (project number 152862, PI Albert Hafner) and as part of the XRONOS project, also funded by the SNSF (project number 198153, PI Martin Hinz). The development of the openness index took place within the framework of the project Time and Temporality in Archaeology (project number 194326, PI Caroline Heitz), inspired by the cooperation within the project QuantHum (project 169371, PI Marco Conedera), both also funded by the SNSF. Jan Kolář was supported by a long-term research development project (RV67985939) and by a grant from the Czech Science Foundation (19-20970Y). We also thank the Institute of Archaeological Sciences of the University of Bern for its support and faith in the outcome of our modelling project. Finally, we thank (already) the unknown reviewers for their helpful comments, which will certainly improve this manuscript significantly.

# Code availability
The computer code used to generate the Bayesian Population model is provided in full in the Supplementary Information, together with information about the program and version used. The R code and Data are available online at https://github.com/MartinHinz/bayesian.demographic.reconstruction.2022 and is archived at https://doi.org/10.5281/zenodo.6594498.

\newpage

# References

::: {#refs}
:::

\newpage

# Author contributions
- *Martin Hinz*: Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Data Curation, Writing - Original Draft, Writing - Review & Editing, Visualization
- *Joe Roe*: Software, Validation, Writing - Review & Editing
- *Julian Laabs*: Investigation, Data Curation, Writing - Review & Editing
- *Caroline Heitz*: Conceptualization, Investigation, Writing - Review & Editing
- *Jan Kolář*: Conceptualization, Writing - Review & Editing

# Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies:

```{r colophon, cache = FALSE}
# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```
